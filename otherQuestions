Welcome to Ubuntu 20.04.6 LTS (GNU/Linux 5.15.0-1074-gcp x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/pro

 System information as of Wed Jan 22 21:18:30 UTC 2025

  System load:  0.0               Processes:             105
  Usage of /:   69.6% of 9.51GB   Users logged in:       0
  Memory usage: 8%                IPv4 address for ens4: 10.154.0.2
  Swap usage:   0%

 * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s
   just raised the bar for easy, resilient and secure K8s cluster deployment.

   https://ubuntu.com/engage/secure-kubernetes-at-the-edge

Expanded Security Maintenance for Applications is not enabled.

0 updates can be applied immediately.

Enable ESM Apps to receive additional future security updates.
See https://ubuntu.com/esm or run: sudo pro status


Last login: Tue Jan 21 00:17:52 2025 from 35.235.248.240
yifan_wang1105@docker-19jan:~$ sudo apt update
Hit:1 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal InRelease
Get:2 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal-updates InRelease [128 kB]
Get:3 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal-backports InRelease [128 kB]
Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [128 kB]        
Get:5 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3745 kB]
Get:6 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1254 kB]
Get:7 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [3367 kB]
Get:8 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1031 kB]
Fetched 9780 kB in 3s (3734 kB/s)                     
Reading package lists... Done
Building dependency tree       
Reading state information... Done
All packages are up to date.
yifan_wang1105@docker-19jan:~$ sudo apt install -y docker.io docker-compose
Reading package lists... Done
Building dependency tree       
Reading state information... Done
docker.io is already the newest version (24.0.7-0ubuntu2~20.04.1).
The following additional packages will be installed:
  python3-cached-property python3-docker python3-dockerpty python3-docopt python3-texttable python3-websocket
The following NEW packages will be installed:
  docker-compose python3-cached-property python3-docker python3-dockerpty python3-docopt python3-texttable python3-websocket
0 upgraded, 7 newly installed, 0 to remove and 0 not upgraded.
Need to get 262 kB of archives.
After this operation, 1616 kB of additional disk space will be used.
Get:1 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal/universe amd64 python3-cached-property all 1.5.1-4 [10.9 kB]
Get:2 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal/universe amd64 python3-websocket all 0.53.0-2ubuntu1 [32.3 kB]
Get:3 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal/universe amd64 python3-docker all 4.1.0-1 [83.8 kB]
Get:4 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal/universe amd64 python3-dockerpty all 0.4.1-2 [11.1 kB]
Get:5 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal/universe amd64 python3-docopt all 0.6.2-2.2ubuntu1 [19.7 kB]
Get:6 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal/universe amd64 python3-texttable all 1.6.2-2 [11.0 kB]
Get:7 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal/universe amd64 docker-compose all 1.25.0-1 [92.7 kB]
Fetched 262 kB in 0s (2386 kB/s)          
Selecting previously unselected package python3-cached-property.
(Reading database ... 62624 files and directories currently installed.)
Preparing to unpack .../0-python3-cached-property_1.5.1-4_all.deb ...
Unpacking python3-cached-property (1.5.1-4) ...
Selecting previously unselected package python3-websocket.
Preparing to unpack .../1-python3-websocket_0.53.0-2ubuntu1_all.deb ...
Unpacking python3-websocket (0.53.0-2ubuntu1) ...
Selecting previously unselected package python3-docker.
Preparing to unpack .../2-python3-docker_4.1.0-1_all.deb ...
Unpacking python3-docker (4.1.0-1) ...
Selecting previously unselected package python3-dockerpty.
Preparing to unpack .../3-python3-dockerpty_0.4.1-2_all.deb ...
Unpacking python3-dockerpty (0.4.1-2) ...
Selecting previously unselected package python3-docopt.
Preparing to unpack .../4-python3-docopt_0.6.2-2.2ubuntu1_all.deb ...
Unpacking python3-docopt (0.6.2-2.2ubuntu1) ...
Selecting previously unselected package python3-texttable.
Preparing to unpack .../5-python3-texttable_1.6.2-2_all.deb ...
Unpacking python3-texttable (1.6.2-2) ...
Selecting previously unselected package docker-compose.
Preparing to unpack .../6-docker-compose_1.25.0-1_all.deb ...
Unpacking docker-compose (1.25.0-1) ...
Setting up python3-cached-property (1.5.1-4) ...
Setting up python3-texttable (1.6.2-2) ...
Setting up python3-docopt (0.6.2-2.2ubuntu1) ...
Setting up python3-websocket (0.53.0-2ubuntu1) ...
update-alternatives: using /usr/bin/python3-wsdump to provide /usr/bin/wsdump (wsdump) in auto mode
Setting up python3-dockerpty (0.4.1-2) ...
Setting up python3-docker (4.1.0-1) ...
Setting up docker-compose (1.25.0-1) ...
Processing triggers for man-db (2.9.1-1) ...
yifan_wang1105@docker-19jan:~$ sudo systemctl start docker
yifan_wang1105@docker-19jan:~$ sudo systemctl enable docker
yifan_wang1105@docker-19jan:~$ mkdir postgres_project && cd postgres_project
yifan_wang1105@docker-19jan:~/postgres_project$ nano docker-compose.yml
yifan_wang1105@docker-19jan:~/postgres_project$ sudo docker-compose up -d
ERROR: The Compose file './docker-compose.yml' is invalid because:
Unsupported config option for services: 'pgadmin'
Unsupported config option for volumes: 'vol-pgdata'
yifan_wang1105@docker-19jan:~/postgres_project$ docker-compose --version
docker-compose version 1.25.0, build unknown
yifan_wang1105@docker-19jan:~/postgres_project$ sudo apt remove docker-compose
Reading package lists... Done
Building dependency tree       
Reading state information... Done
The following packages were automatically installed and are no longer required:
  python3-cached-property python3-docker python3-dockerpty python3-docopt python3-texttable python3-websocket
Use 'sudo apt autoremove' to remove them.
The following packages will be REMOVED:
  docker-compose
0 upgraded, 0 newly installed, 1 to remove and 0 not upgraded.
After this operation, 667 kB disk space will be freed.
Do you want to continue? [Y/n] y
(Reading database ... 62869 files and directories currently installed.)
Removing docker-compose (1.25.0-1) ...
Processing triggers for man-db (2.9.1-1) ...
yifan_wang1105@docker-19jan:~/postgres_project$ sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100 61.6M  100 61.6M    0     0  66.5M      0 --:--:-- --:--:-- --:--:-- 66.5M
yifan_wang1105@docker-19jan:~/postgres_project$ sudo chmod +x /usr/local/bin/docker-compose
yifan_wang1105@docker-19jan:~/postgres_project$ sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100 61.6M  100 61.6M    0     0  96.8M      0 --:--:-- --:--:-- --:--:-- 96.8M
yifan_wang1105@docker-19jan:~/postgres_project$ sudo chmod +x /usr/local/bin/docker-compose
yifan_wang1105@docker-19jan:~/postgres_project$ docker-compose --version
-bash: /usr/bin/docker-compose: No such file or directory
yifan_wang1105@docker-19jan:~/postgres_project$ which docker-compose
/usr/local/bin/docker-compose
yifan_wang1105@docker-19jan:~/postgres_project$ sudo rm /usr/local/bin/docker-compose
yifan_wang1105@docker-19jan:~/postgres_project$ sudo rm /usr/bin/docker-compose
rm: cannot remove '/usr/bin/docker-compose': No such file or directory
yifan_wang1105@docker-19jan:~/postgres_project$ sudo rm /usr/local/bin/docker-compose
rm: cannot remove '/usr/local/bin/docker-compose': No such file or directory
yifan_wang1105@docker-19jan:~/postgres_project$ sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100 61.6M  100 61.6M    0     0  73.1M      0 --:--:-- --:--:-- --:--:--  319M
yifan_wang1105@docker-19jan:~/postgres_project$ sudo chmod +x /usr/local/bin/docker-compose
yifan_wang1105@docker-19jan:~/postgres_project$ docker-compose --version
-bash: /usr/bin/docker-compose: No such file or directory
yifan_wang1105@docker-19jan:~/postgres_project$ ls -l /usr/local/bin/docker-compose
-rwxr-xr-x 1 root root 64694701 Jan 22 21:40 /usr/local/bin/docker-compose
yifan_wang1105@docker-19jan:~/postgres_project$ sudo chmod +x /usr/local/bin/docker-compose
yifan_wang1105@docker-19jan:~/postgres_project$ sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100 61.6M  100 61.6M    0     0  99.5M      0 --:--:-- --:--:-- --:--:-- 99.5M
yifan_wang1105@docker-19jan:~/postgres_project$ ls -l /usr/local/bin/docker-compose
-rwxr-xr-x 1 root root 64694701 Jan 22 21:42 /usr/local/bin/docker-compose
yifan_wang1105@docker-19jan:~/postgres_project$ sudo chmod +x /usr/local/bin/docker-compose
yifan_wang1105@docker-19jan:~/postgres_project$ sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
yifan_wang1105@docker-19jan:~/postgres_project$ sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
ln: failed to create symbolic link '/usr/bin/docker-compose': File exists
yifan_wang1105@docker-19jan:~/postgres_project$ docker-compose --version
Docker Compose version v2.32.4
yifan_wang1105@docker-19jan:~/postgres_project$ ls
docker-compose.yml
yifan_wang1105@docker-19jan:~/postgres_project$ nano docker-compose.yml 
yifan_wang1105@docker-19jan:~/postgres_project$ sudo docker -compose up -d
unknown shorthand flag: 'd' in -d
See 'docker --help'.

Usage:  docker [OPTIONS] COMMAND

A self-sufficient runtime for containers

Common Commands:
  run         Create and run a new container from an image
  exec        Execute a command in a running container
  ps          List containers
  build       Build an image from a Dockerfile
  pull        Download an image from a registry
  push        Upload an image to a registry
  images      List images
  login       Log in to a registry
  logout      Log out from a registry
  search      Search Docker Hub for images
  version     Show the Docker version information
  info        Display system-wide information

Management Commands:
  builder     Manage builds
  container   Manage containers
  context     Manage contexts
  image       Manage images
  manifest    Manage Docker image manifests and manifest lists
  network     Manage networks
  plugin      Manage plugins
  system      Manage Docker
  trust       Manage trust on Docker images
  volume      Manage volumes

Swarm Commands:
  config      Manage Swarm configs
  node        Manage Swarm nodes
  secret      Manage Swarm secrets
  service     Manage Swarm services
  stack       Manage Swarm stacks
  swarm       Manage Swarm

Commands:
  attach      Attach local standard input, output, and error streams to a running container
  commit      Create a new image from a container's changes
  cp          Copy files/folders between a container and the local filesystem
  create      Create a new container
  diff        Inspect changes to files or directories on a container's filesystem
  events      Get real time events from the server
  export      Export a container's filesystem as a tar archive
  history     Show the history of an image
  import      Import the contents from a tarball to create a filesystem image
  inspect     Return low-level information on Docker objects
  kill        Kill one or more running containers
  load        Load an image from a tar archive or STDIN
  logs        Fetch the logs of a container
  pause       Pause all processes within one or more containers
  port        List port mappings or a specific mapping for the container
  rename      Rename a container
  restart     Restart one or more containers
  rm          Remove one or more containers
  rmi         Remove one or more images
  save        Save one or more images to a tar archive (streamed to STDOUT by default)
  start       Start one or more stopped containers
  stats       Display a live stream of container(s) resource usage statistics
  stop        Stop one or more running containers
  tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE
  top         Display the running processes of a container
  unpause     Unpause all processes within one or more containers
  update      Update configuration of one or more containers
  wait        Block until one or more containers stop, then print their exit codes

Global Options:
      --config string      Location of client config files (default "/root/.docker")
  -c, --context string     Name of the context to use to connect to the daemon (overrides DOCKER_HOST env var and default context set with "docker context use")
  -D, --debug              Enable debug mode
  -H, --host list          Daemon socket to connect to
  -l, --log-level string   Set the logging level ("debug", "info", "warn", "error", "fatal") (default "info")
      --tls                Use TLS; implied by --tlsverify
      --tlscacert string   Trust certs signed only by this CA (default "/root/.docker/ca.pem")
      --tlscert string     Path to TLS certificate file (default "/root/.docker/cert.pem")
      --tlskey string      Path to TLS key file (default "/root/.docker/key.pem")
      --tlsverify          Use TLS and verify the remote
  -v, --version            Print version information and quit

Run 'docker COMMAND --help' for more information on a command.

For more help on how to use Docker, head to https://docs.docker.com/go/guides/

yifan_wang1105@docker-19jan:~/postgres_project$ sudo docker-compose up -d
[+] Running 28/28
 ✔ pgadmin Pulled                                                                                                                                                              32.3s 
   ✔ 38a8310d387e Pull complete                                                                                                                                                 0.8s 
   ✔ 087843ea2956 Pull complete                                                                                                                                                25.5s 
   ✔ 6db836a75a2d Pull complete                                                                                                                                                25.7s 
   ✔ 5d0e4706d110 Pull complete                                                                                                                                                25.7s 
   ✔ 31ebcef82521 Pull complete                                                                                                                                                25.7s 
   ✔ 91551c39a7c3 Pull complete                                                                                                                                                25.8s 
   ✔ 210d55276a54 Pull complete                                                                                                                                                25.8s 
   ✔ 0f3a11d54a10 Pull complete                                                                                                                                                25.8s 
   ✔ dcd3056dbb91 Pull complete                                                                                                                                                27.4s 
   ✔ 545d1f431f52 Pull complete                                                                                                                                                28.3s 
   ✔ 48449e1741e8 Pull complete                                                                                                                                                28.3s 
   ✔ 1213e95defdb Pull complete                                                                                                                                                28.3s 
   ✔ 55c17a7b26f0 Pull complete                                                                                                                                                28.4s 
   ✔ 31af12c6548e Pull complete                                                                                                                                                28.4s 
   ✔ 93a2e5af292e Pull complete                                                                                                                                                28.4s 
   ✔ 609a99bd4f87 Pull complete                                                                                                                                                30.8s 
 ✔ db Pulled                                                                                                                                                                   21.9s 
   ✔ 1f3e46996e29 Pull complete                                                                                                                                                 3.4s 
   ✔ 1ddaf56854cd Pull complete                                                                                                                                                 3.4s 
   ✔ 3cf4f77660fd Pull complete                                                                                                                                                 3.7s 
   ✔ f562efc34463 Pull complete                                                                                                                                                 3.8s 
   ✔ d6eaa17dfd6a Pull complete                                                                                                                                                20.1s 
   ✔ fdcefadb5bb3 Pull complete                                                                                                                                                20.2s 
   ✔ badd2a25d9ca Pull complete                                                                                                                                                20.3s 
   ✔ f699f32c0574 Pull complete                                                                                                                                                20.3s 
   ✔ 75de42a401ce Pull complete                                                                                                                                                20.4s 
   ✔ c48dc11d8978 Pull complete                                                                                                                                                20.4s 
[+] Running 5/5
 ✔ Network postgres_project_default  Created                                                                                                                                    0.1s 
 ✔ Volume "vol-pgdata"               Created                                                                                                                                    0.0s 
 ✔ Volume "vol-pgadmin_data"         Created                                                                                                                                    0.0s 
 ✔ Container pgadmin                 Started                                                                                                                                    3.2s 
 ✔ Container postgres                Started                                                                                                                                    3.2s 
yifan_wang1105@docker-19jan:~/postgres_project$ sudo docker ps
CONTAINER ID   IMAGE                   COMMAND                  CREATED              STATUS              PORTS                                            NAMES
eb6d328f7e86   postgres:17-alpine      "docker-entrypoint.s…"   About a minute ago   Up About a minute   0.0.0.0:5433->5432/tcp, :::5433->5432/tcp        postgres
ecbbf581863e   dpage/pgadmin4:latest   "/entrypoint.sh"         About a minute ago   Up About a minute   443/tcp, 0.0.0.0:8080->80/tcp, :::8080->80/tcp   pgadmin
yifan_wang1105@docker-19jan:~/postgres_project$ wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz
--2025-01-22 22:04:12--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz
Resolving github.com (github.com)... 20.26.156.215
Connecting to github.com (github.com)|20.26.156.215|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/ea580e9e-555c-4bd0-ae73-43051d8e7c0b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250122T220412Z&X-Amz-Expires=300&X-Amz-Signature=247f22de2203b73d5ec3454f7cd10b99b863887fa56817b365c8178e1d5e3009&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]
--2025-01-22 22:04:12--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/ea580e9e-555c-4bd0-ae73-43051d8e7c0b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250122T220412Z&X-Amz-Expires=300&X-Amz-Signature=247f22de2203b73d5ec3454f7cd10b99b863887fa56817b365c8178e1d5e3009&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 8262584 (7.9M) [application/octet-stream]
Saving to: ‘green_tripdata_2019-10.csv.gz’

green_tripdata_2019-10.csv.gz                 100%[==============================================================================================>]   7.88M  --.-KB/s    in 0.04s   

2025-01-22 22:04:12 (210 MB/s) - ‘green_tripdata_2019-10.csv.gz’ saved [8262584/8262584]

yifan_wang1105@docker-19jan:~/postgres_project$ wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv
--2025-01-22 22:04:12--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv
Resolving github.com (github.com)... 20.26.156.215
Connecting to github.com (github.com)|20.26.156.215|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250122T220412Z&X-Amz-Expires=300&X-Amz-Signature=01d665821b4d99349e6f186d8ca3d7b3cb7b1a88e9506f4291ac14e78db90db4&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]
--2025-01-22 22:04:12--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250122T220412Z&X-Amz-Expires=300&X-Amz-Signature=01d665821b4d99349e6f186d8ca3d7b3cb7b1a88e9506f4291ac14e78db90db4&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 12322 (12K) [application/octet-stream]
Saving to: ‘taxi_zone_lookup.csv’

taxi_zone_lookup.csv                          100%[==============================================================================================>]  12.03K  --.-KB/s    in 0s      

2025-01-22 22:04:13 (55.3 MB/s) - ‘taxi_zone_lookup.csv’ saved [12322/12322]

yifan_wang1105@docker-19jan:~/postgres_project$ gunzip green_tripdata_2019-10.csv.gz
yifan_wang1105@docker-19jan:~/postgres_project$ sudo apt install postgresql-client
Reading package lists... Done
Building dependency tree       
Reading state information... Done
The following packages were automatically installed and are no longer required:
  python3-cached-property python3-docker python3-dockerpty python3-docopt python3-texttable python3-websocket
Use 'sudo apt autoremove' to remove them.
The following additional packages will be installed:
  libpq5 postgresql-client-12 postgresql-client-common
Suggested packages:
  postgresql-12 postgresql-doc-12
The following NEW packages will be installed:
  libpq5 postgresql-client postgresql-client-12 postgresql-client-common
0 upgraded, 4 newly installed, 0 to remove and 0 not upgraded.
Need to get 1206 kB of archives.
After this operation, 4485 kB of additional disk space will be used.
Do you want to continue? [Y/n] y
Get:1 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal-updates/main amd64 libpq5 amd64 12.22-0ubuntu0.20.04.1 [117 kB]
Get:2 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal-updates/main amd64 postgresql-client-common all 214ubuntu0.1 [28.2 kB]
Get:3 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal-updates/main amd64 postgresql-client-12 amd64 12.22-0ubuntu0.20.04.1 [1056 kB]
Get:4 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal-updates/main amd64 postgresql-client all 12+214ubuntu0.1 [3940 B]
Fetched 1206 kB in 0s (10.9 MB/s)           
Selecting previously unselected package libpq5:amd64.
(Reading database ... 62797 files and directories currently installed.)
Preparing to unpack .../libpq5_12.22-0ubuntu0.20.04.1_amd64.deb ...
Unpacking libpq5:amd64 (12.22-0ubuntu0.20.04.1) ...
Selecting previously unselected package postgresql-client-common.
Preparing to unpack .../postgresql-client-common_214ubuntu0.1_all.deb ...
Unpacking postgresql-client-common (214ubuntu0.1) ...
Selecting previously unselected package postgresql-client-12.
Preparing to unpack .../postgresql-client-12_12.22-0ubuntu0.20.04.1_amd64.deb ...
Unpacking postgresql-client-12 (12.22-0ubuntu0.20.04.1) ...
Selecting previously unselected package postgresql-client.
Preparing to unpack .../postgresql-client_12+214ubuntu0.1_all.deb ...
Unpacking postgresql-client (12+214ubuntu0.1) ...
Setting up postgresql-client-common (214ubuntu0.1) ...
Setting up libpq5:amd64 (12.22-0ubuntu0.20.04.1) ...
Setting up postgresql-client-12 (12.22-0ubuntu0.20.04.1) ...
update-alternatives: using /usr/share/postgresql/12/man/man1/psql.1.gz to provide /usr/share/man/man1/psql.1.gz (psql.1.gz) in auto mode
Setting up postgresql-client (12+214ubuntu0.1) ...
Processing triggers for man-db (2.9.1-1) ...
Processing triggers for libc-bin (2.31-0ubuntu9.16) ...
yifan_wang1105@docker-19jan:~/postgres_project$ psql -h localhost -p 5433 -U postgres -d ny_taxi
Password for user postgres: 
psql: error: fe_sendauth: no password supplied
yifan_wang1105@docker-19jan:~/postgres_project$ psql -h localhost -p 5433 -U postgres -d ny_taxi
Password for user postgres: 
psql (12.22 (Ubuntu 12.22-0ubuntu0.20.04.1), server 17.2)
WARNING: psql major version 12, server major version 17.
         Some psql features might not work.
Type "help" for help.

ny_taxi=# CREATE TABLE green_tripdata (
ny_taxi(#     -- Define columns based on CSV structure
ny_taxi(# );
CREATE TABLE
ny_taxi=# 
ny_taxi=# CREATE TABLE taxi_zone_lookup (
ny_taxi(#     -- Define columns based on CSV structure
ny_taxi(# );
CREATE TABLE
ny_taxi=# 
ny_taxi=# \COPY green_tripdata FROM 'green_tripdata_2019-10.csv' CSV HEADER;
ERROR:  extra data after last expected column
CONTEXT:  COPY green_tripdata, line 2: "2,2019-10-01 00:26:02,2019-10-01 00:39:58,N,1,112,196,1,5.88,18,0.5,0.5,0,0,,0.3,19.3,2,1,0"
ny_taxi=# \COPY taxi_zone_lookup FROM 'taxi_zone_lookup.csv' CSV HEADER;
ERROR:  extra data after last expected column
CONTEXT:  COPY taxi_zone_lookup, line 2: "1,"EWR","Newark Airport","EWR""
ny_taxi=# head -n 5 green_tripdata_2019-10.csv
ny_taxi-# head -n 5 taxi_zone_lookup.csv
ny_taxi-# 
ny_taxi-# \q
yifan_wang1105@docker-19jan:~/postgres_project$ wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz
--2025-01-22 22:14:27--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz
Resolving github.com (github.com)... 20.26.156.215
Connecting to github.com (github.com)|20.26.156.215|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/ea580e9e-555c-4bd0-ae73-43051d8e7c0b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250122T221427Z&X-Amz-Expires=300&X-Amz-Signature=ad78a8fb0c678898f9e1fa14cfd0ac85332b50cb997c58998d7d1ecfe68b154f&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]
--2025-01-22 22:14:27--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/ea580e9e-555c-4bd0-ae73-43051d8e7c0b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250122T221427Z&X-Amz-Expires=300&X-Amz-Signature=ad78a8fb0c678898f9e1fa14cfd0ac85332b50cb997c58998d7d1ecfe68b154f&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 8262584 (7.9M) [application/octet-stream]
Saving to: ‘green_tripdata_2019-10.csv.gz’

green_tripdata_2019-10.csv.gz                 100%[==============================================================================================>]   7.88M  --.-KB/s    in 0.05s   

2025-01-22 22:14:28 (172 MB/s) - ‘green_tripdata_2019-10.csv.gz’ saved [8262584/8262584]

yifan_wang1105@docker-19jan:~/postgres_project$ wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv
--2025-01-22 22:14:28--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv
Resolving github.com (github.com)... 20.26.156.215
Connecting to github.com (github.com)|20.26.156.215|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250122T221428Z&X-Amz-Expires=300&X-Amz-Signature=d97b7b561178f0acdcee8f1d0eb5eecffa9a6240d17c2b781af8d16291fe7dd4&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]
--2025-01-22 22:14:28--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250122T221428Z&X-Amz-Expires=300&X-Amz-Signature=d97b7b561178f0acdcee8f1d0eb5eecffa9a6240d17c2b781af8d16291fe7dd4&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 12322 (12K) [application/octet-stream]
Saving to: ‘taxi_zone_lookup.csv.1’

taxi_zone_lookup.csv.1                        100%[==============================================================================================>]  12.03K  --.-KB/s    in 0s      

2025-01-22 22:14:28 (49.2 MB/s) - ‘taxi_zone_lookup.csv.1’ saved [12322/12322]

yifan_wang1105@docker-19jan:~/postgres_project$ gunzip green_tripdata_2019-10.csv.gz
gzip: green_tripdata_2019-10.csv already exists; do you wish to overwrite (y or n)? y
yifan_wang1105@docker-19jan:~/postgres_project$ head -n 5 green_tripdata_2019-10.csv
VendorID,lpep_pickup_datetime,lpep_dropoff_datetime,store_and_fwd_flag,RatecodeID,PULocationID,DOLocationID,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type,congestion_surcharge
2,2019-10-01 00:26:02,2019-10-01 00:39:58,N,1,112,196,1,5.88,18,0.5,0.5,0,0,,0.3,19.3,2,1,0
1,2019-10-01 00:18:11,2019-10-01 00:22:38,N,1,43,263,1,.80,5,3.25,0.5,0,0,,0.3,9.05,2,1,0
1,2019-10-01 00:09:31,2019-10-01 00:24:47,N,1,255,228,2,7.50,21.5,0.5,0.5,0,0,,0.3,22.8,2,1,0
1,2019-10-01 00:37:40,2019-10-01 00:41:49,N,1,181,181,1,.90,5.5,0.5,0.5,0,0,,0.3,6.8,2,1,0
yifan_wang1105@docker-19jan:~/postgres_project$ head -n 5 taxi_zone_lookup.csv
"LocationID","Borough","Zone","service_zone"
1,"EWR","Newark Airport","EWR"
2,"Queens","Jamaica Bay","Boro Zone"
3,"Bronx","Allerton/Pelham Gardens","Boro Zone"
4,"Manhattan","Alphabet City","Yellow Zone"
yifan_wang1105@docker-19jan:~/postgres_project$ psql -h localhost -p 5433 postgres -d ny_taxi
Password for user postgres: 
psql (12.22 (Ubuntu 12.22-0ubuntu0.20.04.1), server 17.2)
WARNING: psql major version 12, server major version 17.
         Some psql features might not work.
Type "help" for help.

ny_taxi=# CREATE TABLE taxi_zone_lookup (
ny_taxi(#     LocationID INTEGER PRIMARY KEY,
ny_taxi(#     Borough VARCHAR(255),
ny_taxi(#     Zone VARCHAR(255),
ny_taxi(#     service_zone VARCHAR(255)
ny_taxi(# );
ERROR:  relation "taxi_zone_lookup" already exists
ny_taxi=# DROP TABLE taxi_zone_lookup;
DROP TABLE
ny_taxi=# CREATE TABLE taxi_zone_lookup (
ny_taxi(#     LocationID INTEGER PRIMARY KEY,
ny_taxi(#     Borough VARCHAR(255),
ny_taxi(#     Zone VARCHAR(255),
ny_taxi(#     service_zone VARCHAR(255)
ny_taxi(# );
CREATE TABLE
ny_taxi=# \COPY taxi_zone_lookup FROM './taxi_zone_lookup.csv' CSV HEADER;
COPY 265
ny_taxi=# SELECT * FROM taxi_zone_lookup LIMIT 5;
 locationid |    borough    |          zone           | service_zone 
------------+---------------+-------------------------+--------------
          1 | EWR           | Newark Airport          | EWR
          2 | Queens        | Jamaica Bay             | Boro Zone
          3 | Bronx         | Allerton/Pelham Gardens | Boro Zone
          4 | Manhattan     | Alphabet City           | Yellow Zone
          5 | Staten Island | Arden Heights           | Boro Zone
(5 rows)

ny_taxi=# head -n 5 green_tripdata_2019-10.csv
ny_taxi-# head -n 5 green_tripdata_2019-10.csv
ny_taxi-# \q
yifan_wang1105@docker-19jan:~/postgres_project$ ls -l green_tripdata_2019-10.csv
-rw-rw-r-- 1 yifan_wang1105 yifan_wang1105 43540725 Jul 14  2022 green_tripdata_2019-10.csv
yifan_wang1105@docker-19jan:~/postgres_project$ head -n 5 green_tripdata_2019-10.csv
VendorID,lpep_pickup_datetime,lpep_dropoff_datetime,store_and_fwd_flag,RatecodeID,PULocationID,DOLocationID,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type,congestion_surcharge
2,2019-10-01 00:26:02,2019-10-01 00:39:58,N,1,112,196,1,5.88,18,0.5,0.5,0,0,,0.3,19.3,2,1,0
1,2019-10-01 00:18:11,2019-10-01 00:22:38,N,1,43,263,1,.80,5,3.25,0.5,0,0,,0.3,9.05,2,1,0
1,2019-10-01 00:09:31,2019-10-01 00:24:47,N,1,255,228,2,7.50,21.5,0.5,0.5,0,0,,0.3,22.8,2,1,0
1,2019-10-01 00:37:40,2019-10-01 00:41:49,N,1,181,181,1,.90,5.5,0.5,0.5,0,0,,0.3,6.8,2,1,0
yifan_wang1105@docker-19jan:~/postgres_project$ ^C
yifan_wang1105@docker-19jan:~/postgres_project$ psql -h localhost -p 5433 postgres -d ny_taxi
Password for user postgres: 
psql (12.22 (Ubuntu 12.22-0ubuntu0.20.04.1), server 17.2)
WARNING: psql major version 12, server major version 17.
         Some psql features might not work.
Type "help" for help.

ny_taxi=# CREATE TABLE green_tripdata (
ny_taxi(#     VendorID INTEGER,
ny_taxi(#     lpep_pickup_datetime TIMESTAMP,
ny_taxi(#     lpep_dropoff_datetime TIMESTAMP,
ny_taxi(#     store_and_fwd_flag VARCHAR(1),
ny_taxi(#     RatecodeID INTEGER,
ny_taxi(#     PULocationID INTEGER,
ny_taxi(#     DOLocationID INTEGER,
ny_taxi(#     passenger_count INTEGER,
ny_taxi(#     trip_distance FLOAT,
ny_taxi(#     fare_amount FLOAT,
ny_taxi(#     extra FLOAT,
ny_taxi(#     mta_tax FLOAT,
ny_taxi(#     tip_amount FLOAT,
ny_taxi(#     tolls_amount FLOAT,
ny_taxi(#     ehail_fee FLOAT,
ny_taxi(#     improvement_surcharge FLOAT,
ny_taxi(#     total_amount FLOAT,
ny_taxi(#     payment_type INTEGER,
ny_taxi(#     trip_type INTEGER,
ny_taxi(#     congestion_surcharge FLOAT
ny_taxi(# );
ERROR:  relation "green_tripdata" already exists
ny_taxi=# DROP TABLE IF EXISTS green_tripdata;
DROP TABLE
ny_taxi=# CREATE TABLE green_tripdata (
ny_taxi(#     VendorID INTEGER,
ny_taxi(#     lpep_pickup_datetime TIMESTAMP,
ny_taxi(#     lpep_dropoff_datetime TIMESTAMP,
ny_taxi(#     store_and_fwd_flag VARCHAR(1),
ny_taxi(#     RatecodeID INTEGER,
ny_taxi(#     PULocationID INTEGER,
ny_taxi(#     DOLocationID INTEGER,
ny_taxi(#     passenger_count INTEGER,
ny_taxi(#     trip_distance FLOAT,
ny_taxi(#     fare_amount FLOAT,
ny_taxi(#     extra FLOAT,
ny_taxi(#     mta_tax FLOAT,
ny_taxi(#     tip_amount FLOAT,
ny_taxi(#     tolls_amount FLOAT,
ny_taxi(#     ehail_fee FLOAT,
ny_taxi(#     improvement_surcharge FLOAT,
ny_taxi(#     total_amount FLOAT,
ny_taxi(#     payment_type INTEGER,
ny_taxi(#     trip_type INTEGER,
ny_taxi(#     congestion_surcharge FLOAT
ny_taxi(# );
CREATE TABLE
ny_taxi=# \COPY green_tripdata FROM './green_tripdata_2019-10.csv' CSV HEADER;

COPY 476386
ny_taxi=# 
ny_taxi=# SELECT * FROM green_tripdata LIMIT 5;
ny_taxi=# SELECT
ny_taxi-#     SUM(CASE WHEN trip_distance <= 1 THEN 1 ELSE 0 END) AS "Up to 1 mile",
ny_taxi-#     SUM(CASE WHEN trip_distance > 1 AND trip_distance <= 3 THEN 1 ELSE 0 END) AS "1 to 3 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 3 AND trip_distance <= 7 THEN 1 ELSE 0 END) AS "3 to 7 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 7 AND trip_distance <= 10 THEN 1 ELSE 0 END) AS "7 to 10 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 10 THEN 1 ELSE 0 END) AS "Over 10 miles"
ny_taxi-# FROM green_tripdata
ny_taxi-# WHERE lpep_pickup_datetime >= '2019-10-01 00:00:00'
ny_taxi-#   AND lpep_pickup_datetime < '2019-11-01 00:00:00';
 Up to 1 mile | 1 to 3 miles | 3 to 7 miles | 7 to 10 miles | Over 10 miles 
--------------+--------------+--------------+---------------+---------------
       104830 |       198995 |       109642 |         27686 |         35201
(1 row)

ny_taxi=# SELECT 
ny_taxi-#     MIN(lpep_pickup_datetime) AS earliest_pickup,
ny_taxi-#     MAX(lpep_pickup_datetime) AS latest_pickup
ny_taxi-# FROM green_tripdata;
   earliest_pickup   |    latest_pickup    
---------------------+---------------------
 2008-10-21 15:52:05 | 2019-11-13 08:46:52
(1 row)

ny_taxi=# SELECT
ny_taxi-#     SUM(CASE WHEN trip_distance <= 1 THEN 1 ELSE 0 END) AS "Up to 1 mile",
ny_taxi-#     SUM(CASE WHEN trip_distance > 1 AND trip_distance <= 3 THEN 1 ELSE 0 END) AS "1 to 3 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 3 AND trip_distance <= 7 THEN 1 ELSE 0 END) AS "3 to 7 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 7 AND trip_distance <= 10 THEN 1 ELSE 0 END) AS "7 to 10 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 10 THEN 1 ELSE 0 END) AS "Over 10 miles"
ny_taxi-# FROM green_tripdata
ny_taxi-# WHERE lpep_pickup_datetime >= '2019-10-01 00:00:00'
ny_taxi-#   AND lpep_pickup_datetime < '2019-11-01 00:00:00';
 Up to 1 mile | 1 to 3 miles | 3 to 7 miles | 7 to 10 miles | Over 10 miles 
--------------+--------------+--------------+---------------+---------------
       104830 |       198995 |       109642 |         27686 |         35201
(1 row)

ny_taxi=# SELECT 
ny_taxi-#     MIN(lpep_pickup_datetime) AS earliest_pickup,
ny_taxi-#     MAX(lpep_pickup_datetime) AS latest_pickup
ny_taxi-# FROM green_tripdata;
   earliest_pickup   |    latest_pickup    
---------------------+---------------------
 2008-10-21 15:52:05 | 2019-11-13 08:46:52
(1 row)

ny_taxi=# SELECT
ny_taxi-#     SUM(CASE WHEN trip_distance <= 1 THEN 1 ELSE 0 END) AS "Up to 1 mile",
ny_taxi-#     SUM(CASE WHEN trip_distance > 1 AND trip_distance <= 3 THEN 1 ELSE 0 END) AS "1 to 3 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 3 AND trip_distance <= 7 THEN 1 ELSE 0 END) AS "3 to 7 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 7 AND trip_distance <= 10 THEN 1 ELSE 0 END) AS "7 to 10 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 10 THEN 1 ELSE 0 END) AS "Over 10 miles"
ny_taxi-# FROM green_tripdata
ny_taxi-# WHERE lpep_pickup_datetime >= '2019-10-01 00:00:00'
ny_taxi-#   AND lpep_pickup_datetime < '2019-11-01 00:00:00';
 Up to 1 mile | 1 to 3 miles | 3 to 7 miles | 7 to 10 miles | Over 10 miles 
--------------+--------------+--------------+---------------+---------------
       104830 |       198995 |       109642 |         27686 |         35201
(1 row)

ny_taxi=# SELECT 
ny_taxi-#     MIN(lpep_pickup_datetime) AS earliest_pickup,
ny_taxi-#     MAX(lpep_pickup_datetime) AS latest_pickup
ny_taxi-# FROM green_tripdata;
   earliest_pickup   |    latest_pickup    
---------------------+---------------------
 2008-10-21 15:52:05 | 2019-11-13 08:46:52
(1 row)

ny_taxi=# DELETE FROM green_tripdata
ny_taxi-# WHERE lpep_pickup_datetime < '2019-01-01 00:00:00'
ny_taxi-#    OR lpep_pickup_datetime > '2019-12-31 23:59:59';
DELETE 12
ny_taxi=# SELECT 
ny_taxi-#     MIN(lpep_pickup_datetime) AS earliest_pickup,
ny_taxi-#     MAX(lpep_pickup_datetime) AS latest_pickup
ny_taxi-# FROM green_tripdata;
   earliest_pickup   |    latest_pickup    
---------------------+---------------------
 2019-09-19 19:54:16 | 2019-11-13 08:46:52
(1 row)

ny_taxi=# SELECT
ny_taxi-#     SUM(CASE WHEN trip_distance <= 1 THEN 1 ELSE 0 END) AS "Up to 1 mile",
ny_taxi-#     SUM(CASE WHEN trip_distance > 1 AND trip_distance <= 3 THEN 1 ELSE 0 END) AS "1 to 3 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 3 AND trip_distance <= 7 THEN 1 ELSE 0 END) AS "3 to 7 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 7 AND trip_distance <= 10 THEN 1 ELSE 0 END) AS "7 to 10 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 10 THEN 1 ELSE 0 END) AS "Over 10 miles"
ny_taxi-# FROM green_tripdata
ny_taxi-# WHERE lpep_pickup_datetime >= '2019-10-01 00:00:00'
ny_taxi-#   AND lpep_pickup_datetime < '2019-11-01 00:00:00'
ny_taxi-#   AND lpep_pickup_datetime >= '2019-01-01 00:00:00'
ny_taxi-#   AND lpep_pickup_datetime <= '2019-12-31 23:59:59';
 Up to 1 mile | 1 to 3 miles | 3 to 7 miles | 7 to 10 miles | Over 10 miles 
--------------+--------------+--------------+---------------+---------------
       104830 |       198995 |       109642 |         27686 |         35201
(1 row)

ny_taxi=# SELECT trip_distance, COUNT(*)
ny_taxi-# FROM green_tripdata
ny_taxi-# GROUP BY trip_distance
ny_taxi-# ORDER BY COUNT(*) DESC
ny_taxi-# LIMIT 10;
 trip_distance | count 
---------------+-------
             0 | 13018
             1 |  3737
           0.9 |  3719
           0.8 |  3593
           1.2 |  3546
           1.1 |  3499
           1.4 |  3373
           1.3 |  3372
           0.7 |  3312
           1.5 |  3003
(10 rows)

ny_taxi=# DELETE FROM green_tripdata
ny_taxi-# WHERE ctid NOT IN (
ny_taxi(#     SELECT MIN(ctid)
ny_taxi(#     FROM green_tripdata
ny_taxi(#     GROUP BY *
ny_taxi(# );
ERROR:  syntax error at or near "*"
LINE 5:     GROUP BY *
                     ^
ny_taxi=# SELECT
ny_taxi-#     SUM(CASE WHEN trip_distance <= 1 THEN 1 ELSE 0 END) AS "Up to 1 mile",
ny_taxi-#     SUM(CASE WHEN trip_distance > 1 AND trip_distance <= 3 THEN 1 ELSE 0 END) AS "1 to 3 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 3 AND trip_distance <= 7 THEN 1 ELSE 0 END) AS "3 to 7 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 7 AND trip_distance <= 10 THEN 1 ELSE 0 END) AS "7 to 10 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 10 THEN 1 ELSE 0 END) AS "Over 10 miles"
ny_taxi-# FROM green_tripdata
ny_taxi-# WHERE lpep_pickup_datetime >= '2019-10-01 00:00:00'
ny_taxi-#   AND lpep_pickup_datetime < '2019-11-01 00:00:00'
ny_taxi-#   AND lpep_pickup_datetime >= '2019-01-01 00:00:00'
ny_taxi-#   AND lpep_pickup_datetime <= '2019-12-31 23:59:59';
 Up to 1 mile | 1 to 3 miles | 3 to 7 miles | 7 to 10 miles | Over 10 miles 
--------------+--------------+--------------+---------------+---------------
       104830 |       198995 |       109642 |         27686 |         35201
(1 row)

ny_taxi=# CREATE TABLE filtered_green_tripdata AS
ny_taxi-# SELECT *
ny_taxi-# FROM green_tripdata
ny_taxi-# WHERE lpep_pickup_datetime >= '2019-10-01 00:00:00'
ny_taxi-#   AND lpep_pickup_datetime < '2019-11-01 00:00:00';

SELECT 476354
ny_taxi=# 
ny_taxi=# SELECT
ny_taxi-#     SUM(CASE WHEN trip_distance <= 1 THEN 1 ELSE 0 END) AS "Up to 1 mile",
ny_taxi-#     SUM(CASE WHEN trip_distance > 1 AND trip_distance <= 3 THEN 1 ELSE 0 END) AS "1 to 3 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 3 AND trip_distance <= 7 THEN 1 ELSE 0 END) AS "3 to 7 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 7 AND trip_distance <= 10 THEN 1 ELSE 0 END) AS "7 to 10 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 10 THEN 1 ELSE 0 END) AS "Over 10 miles"
ny_taxi-# FROM filtered_green_tripdata;
 Up to 1 mile | 1 to 3 miles | 3 to 7 miles | 7 to 10 miles | Over 10 miles 
--------------+--------------+--------------+---------------+---------------
       104830 |       198995 |       109642 |         27686 |         35201
(1 row)

ny_taxi=# SELECT COUNT(*)
ny_taxi-# FROM filtered_green_tripdata;
 count  
--------
 476354
(1 row)

ny_taxi=# q
ny_taxi-# \q
yifan_wang1105@docker-19jan:~/postgres_project$ wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz
--2025-01-22 22:54:04--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz
Resolving github.com (github.com)... 20.26.156.215
Connecting to github.com (github.com)|20.26.156.215|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/ea580e9e-555c-4bd0-ae73-43051d8e7c0b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250122T225405Z&X-Amz-Expires=300&X-Amz-Signature=51c8d6a39de0df3a8e480406d6069c7555b70bdf43324732f794372c773dd618&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]
--2025-01-22 22:54:05--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/ea580e9e-555c-4bd0-ae73-43051d8e7c0b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250122T225405Z&X-Amz-Expires=300&X-Amz-Signature=51c8d6a39de0df3a8e480406d6069c7555b70bdf43324732f794372c773dd618&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 8262584 (7.9M) [application/octet-stream]
Saving to: ‘green_tripdata_2019-10.csv.gz’

green_tripdata_2019-10.csv.gz                 100%[==============================================================================================>]   7.88M  --.-KB/s    in 0.04s   

2025-01-22 22:54:05 (190 MB/s) - ‘green_tripdata_2019-10.csv.gz’ saved [8262584/8262584]

yifan_wang1105@docker-19jan:~/postgres_project$ gunzip green_tripdata_2019-10.csv.gz
gzip: green_tripdata_2019-10.csv already exists; do you wish to overwrite (y or n)? y
yifan_wang1105@docker-19jan:~/postgres_project$ DELETE FROM green_tripdata
DELETE: command not found
yifan_wang1105@docker-19jan:~/postgres_project$ WHERE lpep_pickup_datetime < '2019-10-01 00:00:00'
-bash: 2019-10-01 00:00:00: No such file or directory
yifan_wang1105@docker-19jan:~/postgres_project$    OR lpep_pickup_datetime >= '2019-11-01 00:00:00';
OR: command not found
yifan_wang1105@docker-19jan:~/postgres_project$ ^C
yifan_wang1105@docker-19jan:~/postgres_project$ psql -h localhost -p 5433 postgres -d ny_taxi
Password for user postgres: 
psql (12.22 (Ubuntu 12.22-0ubuntu0.20.04.1), server 17.2)
WARNING: psql major version 12, server major version 17.
         Some psql features might not work.
Type "help" for help.

ny_taxi=# DELETE FROM green_tripdata
ny_taxi-# WHERE lpep_pickup_datetime < '2019-10-01 00:00:00'
ny_taxi-#    OR lpep_pickup_datetime >= '2019-11-01 00:00:00';
DELETE 20
ny_taxi=# DELETE FROM green_tripdata
ny_taxi-# WHERE trip_distance < 0
ny_taxi-#    OR trip_distance > 100;
DELETE 3
ny_taxi=# SELECT
ny_taxi-#     SUM(CASE WHEN trip_distance <= 1 THEN 1 ELSE 0 END) AS "Up to 1 mile",
ny_taxi-#     SUM(CASE WHEN trip_distance > 1 AND trip_distance <= 3 THEN 1 ELSE 0 END) AS "1 to 3 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 3 AND trip_distance <= 7 THEN 1 ELSE 0 END) AS "3 to 7 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 7 AND trip_distance <= 10 THEN 1 ELSE 0 END) AS "7 to 10 miles",
ny_taxi-#     SUM(CASE WHEN trip_distance > 10 THEN 1 ELSE 0 END) AS "Over 10 miles"
ny_taxi-# FROM green_tripdata;
 Up to 1 mile | 1 to 3 miles | 3 to 7 miles | 7 to 10 miles | Over 10 miles 
--------------+--------------+--------------+---------------+---------------
       104828 |       198995 |       109642 |         27686 |         35200
(1 row)

ny_taxi=# SELECT trip_distance, COUNT(*)
ny_taxi-# FROM green_tripdata
ny_taxi-# WHERE lpep_pickup_datetime >= '2019-10-01 00:00:00'
ny_taxi-#   AND lpep_pickup_datetime < '2019-11-01 00:00:00'
ny_taxi-# GROUP BY trip_distance
ny_taxi-# ORDER BY trip_distance;
ny_taxi=# 
ny_taxi=# SELECT 
ny_taxi-#     DATE(lpep_pickup_datetime) AS trip_date,
ny_taxi-#     MAX(trip_distance) AS max_distance
ny_taxi-# FROM green_tripdata
ny_taxi-# WHERE lpep_pickup_datetime >= '2019-10-01 00:00:00'
ny_taxi-#   AND lpep_pickup_datetime < '2019-11-01 00:00:00'
ny_taxi-# GROUP BY trip_date
ny_taxi-# ORDER BY max_distance DESC;
 trip_date  | max_distance 
------------+--------------
 2019-10-11 |        95.78
 2019-10-26 |        91.56
 2019-10-24 |        90.75
 2019-10-05 |        85.23
 2019-10-21 |         71.5
 2019-10-14 |        70.03
 2019-10-29 |        66.98
 2019-10-22 |        65.98
 2019-10-17 |        59.74
 2019-10-19 |         57.8
 2019-10-25 |         53.5
 2019-10-12 |        51.14
 2019-10-02 |           50
 2019-10-30 |         49.1
 2019-10-15 |        48.95
 2019-10-13 |        48.95
 2019-10-01 |        47.42
 2019-10-28 |        46.09
 2019-10-07 |         45.9
 2019-10-06 |         45.3
 2019-10-04 |        45.18
 2019-10-03 |        44.07
 2019-10-31 |        43.13
 2019-10-27 |        42.63
 2019-10-18 |        41.29
 2019-10-23 |        40.34
 2019-10-09 |        38.46
 2019-10-20 |        38.29
 2019-10-10 |        36.23
 2019-10-16 |        35.41
 2019-10-08 |        34.75
(31 rows)

ny_taxi=# SELECT *
ny_taxi-# FROM green_tripdata
ny_taxi-# WHERE DATE(lpep_pickup_datetime) = '2019-10-18';
ny_taxi=# 
ny_taxi=# SELECT 
ny_taxi-#     PULocationID,
ny_taxi-#     SUM(total_amount) AS total_revenue
ny_taxi-# FROM green_tripdata
ny_taxi-# WHERE DATE(lpep_pickup_datetime) = '2019-10-18'
ny_taxi-# GROUP BY PULocationID
ny_taxi-# HAVING SUM(total_amount) > 13000
ny_taxi-# ORDER BY total_revenue DESC
ny_taxi-# LIMIT 3;
 pulocationid |   total_revenue    
--------------+--------------------
           74 |  18686.68000000005
           75 | 16797.260000000053
          166 |  13029.79000000003
(3 rows)

ny_taxi=# SELECT 
ny_taxi-#     l.LocationID,
ny_taxi-#     l.zone AS pickup_zone,
ny_taxi-#     t.total_revenue
ny_taxi-# FROM (
ny_taxi(#     SELECT 
ny_taxi(#         PULocationID,
ny_taxi(#         SUM(total_amount) AS total_revenue
ny_taxi(#     FROM green_tripdata
ny_taxi(#     WHERE DATE(lpep_pickup_datetime) = '2019-10-18'
ny_taxi(#     GROUP BY PULocationID
ny_taxi(#     HAVING SUM(total_amount) > 13000
ny_taxi(#     ORDER BY total_revenue DESC
ny_taxi(#     LIMIT 3
ny_taxi(# ) AS t
ny_taxi-# JOIN taxi_zone_lookup l
ny_taxi-# ON t.PULocationID = l.LocationID;
 locationid |     pickup_zone     |   total_revenue    
------------+---------------------+--------------------
         74 | East Harlem North   | 18686.680000000062
         75 | East Harlem South   | 16797.260000000075
        166 | Morningside Heights |  13029.79000000003
(3 rows)

ny_taxi=# SELECT 
ny_taxi-#     l2.zone AS dropoff_zone,
ny_taxi-#     MAX(g.tip_amount) AS max_tip
ny_taxi-# FROM 
ny_taxi-#     green_tripdata g
ny_taxi-# JOIN 
ny_taxi-#     taxi_zone_lookup l1 ON g.PULocationID = l1.LocationID
ny_taxi-# JOIN 
ny_taxi-#     taxi_zone_lookup l2 ON g.DOLocationID = l2.LocationID
ny_taxi-# WHERE 
ny_taxi-#     l1.zone = 'East Harlem North'
ny_taxi-#     AND DATE(g.lpep_pickup_datetime) BETWEEN '2019-10-01' AND '2019-10-31'
ny_taxi-# GROUP BY 
ny_taxi-#     l2.zone
ny_taxi-# ORDER BY 
ny_taxi-#     max_tip DESC
ny_taxi-# LIMIT 1;
 dropoff_zone | max_tip 
--------------+---------
 JFK Airport  |    87.3
(1 row)

ny_taxi=# \q
yifan_wang1105@docker-19jan:~/postgres_project$ sudo apt update
Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [128 kB]
Hit:2 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal InRelease                                
Get:3 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal-updates InRelease [128 kB]
Hit:4 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal-backports InRelease
Get:5 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3746 kB]
Get:6 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal-updates/main Translation-en [572 kB]
Fetched 4574 kB in 2s (2470 kB/s)                             
Reading package lists... Done
Building dependency tree       
Reading state information... Done
1 package can be upgraded. Run 'apt list --upgradable' to see it.
yifan_wang1105@docker-19jan:~/postgres_project$ sudo apt install -y wget unzip
Reading package lists... Done
Building dependency tree       
Reading state information... Done
wget is already the newest version (1.20.3-1ubuntu2.1).
wget set to manually installed.
The following packages were automatically installed and are no longer required:
  python3-cached-property python3-docker python3-dockerpty python3-docopt python3-texttable python3-websocket
Use 'sudo apt autoremove' to remove them.
Suggested packages:
  zip
The following NEW packages will be installed:
  unzip
0 upgraded, 1 newly installed, 0 to remove and 1 not upgraded.
Need to get 169 kB of archives.
After this operation, 593 kB of additional disk space will be used.
Get:1 http://europe-west2.gce.archive.ubuntu.com/ubuntu focal-updates/main amd64 unzip amd64 6.0-25ubuntu1.2 [169 kB]
Fetched 169 kB in 0s (2392 kB/s)
Selecting previously unselected package unzip.
(Reading database ... 63097 files and directories currently installed.)
Preparing to unpack .../unzip_6.0-25ubuntu1.2_amd64.deb ...
Unpacking unzip (6.0-25ubuntu1.2) ...
Setting up unzip (6.0-25ubuntu1.2) ...
Processing triggers for mime-support (3.64ubuntu1) ...
Processing triggers for man-db (2.9.1-1) ...
yifan_wang1105@docker-19jan:~/postgres_project$ wget https://releases.hashicorp.com/terraform/1.5.5/terraform_1.5.5_linux_amd64.zip
--2025-01-22 23:17:01--  https://releases.hashicorp.com/terraform/1.5.5/terraform_1.5.5_linux_amd64.zip
Resolving releases.hashicorp.com (releases.hashicorp.com)... 143.204.68.93, 143.204.68.39, 143.204.68.20, ...
Connecting to releases.hashicorp.com (releases.hashicorp.com)|143.204.68.93|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 21018563 (20M) [application/zip]
Saving to: ‘terraform_1.5.5_linux_amd64.zip’

terraform_1.5.5_linux_amd64.zip          100%[==================================================================================>]  20.04M  --.-KB/s    in 0.1s    

2025-01-22 23:17:01 (144 MB/s) - ‘terraform_1.5.5_linux_amd64.zip’ saved [21018563/21018563]

yifan_wang1105@docker-19jan:~/postgres_project$ unzip terraform_1.5.5_linux_amd64.zip
Archive:  terraform_1.5.5_linux_amd64.zip
  inflating: terraform               
yifan_wang1105@docker-19jan:~/postgres_project$ sudo mv terraform /usr/local/bin/
yifan_wang1105@docker-19jan:~/postgres_project$ terraform --version
Terraform v1.5.5
on linux_amd64

Your version of Terraform is out of date! The latest version
is 1.10.5. You can update by downloading from https://www.terraform.io/downloads.html
yifan_wang1105@docker-19jan:~/postgres_project$ sudo rm /usr/local/bin/terraform
yifan_wang1105@docker-19jan:~/postgres_project$ wget https://releases.hashicorp.com/terraform/1.10.5/terraform_1.10.5_linux_amd64.zip
--2025-01-22 23:18:20--  https://releases.hashicorp.com/terraform/1.10.5/terraform_1.10.5_linux_amd64.zip
Resolving releases.hashicorp.com (releases.hashicorp.com)... 143.204.68.93, 143.204.68.39, 143.204.68.86, ...
Connecting to releases.hashicorp.com (releases.hashicorp.com)|143.204.68.93|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 27714924 (26M) [application/zip]
Saving to: ‘terraform_1.10.5_linux_amd64.zip’

terraform_1.10.5_linux_amd64.zip         100%[==================================================================================>]  26.43M  --.-KB/s    in 0.1s    

2025-01-22 23:18:20 (210 MB/s) - ‘terraform_1.10.5_linux_amd64.zip’ saved [27714924/27714924]

yifan_wang1105@docker-19jan:~/postgres_project$ unzip terraform_1.10.5_linux_amd64.zip
Archive:  terraform_1.10.5_linux_amd64.zip
  inflating: LICENSE.txt             
  inflating: terraform               
yifan_wang1105@docker-19jan:~/postgres_project$ sudo mv terraform /usr/local/bin/
yifan_wang1105@docker-19jan:~/postgres_project$ terraform --version
Terraform v1.10.5
on linux_amd64
yifan_wang1105@docker-19jan:~/postgres_project$ git clone https://github.com/harper-w/data-engineering-zoomcamp.git
Cloning into 'data-engineering-zoomcamp'...
remote: Enumerating objects: 4562, done.
remote: Total 4562 (delta 0), reused 0 (delta 0), pack-reused 4562 (from 1)
Receiving objects: 100% (4562/4562), 7.28 MiB | 18.67 MiB/s, done.
Resolving deltas: 100% (2409/2409), done.
yifan_wang1105@docker-19jan:~/postgres_project$ cd data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform$ terraform init
Terraform initialized in an empty directory!

The directory has no Terraform configuration files. You may begin working
with Terraform immediately by creating Terraform configuration files.
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform$ cd data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform
-bash: cd: data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform: No such file or directory
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform$ cd ..
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp$ cd ..
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform$ cd ..
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp$ cd data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform
-bash: cd: data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform: No such file or directory
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp$ cd ..
yifan_wang1105@docker-19jan:~/postgres_project$ cd data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform$ ls *.tf
ls: cannot access '*.tf': No such file or directory
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform$ cd ..
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp$ cd ..
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform$ cd ..
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp$ cd ..
yifan_wang1105@docker-19jan:~/postgres_project$ cd data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform$ 
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform$ ls
README.md  terraform_basic  terraform_with_variables
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform$ cd terraform_basic
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ ls
main.tf
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ terraform init
Initializing the backend...
Initializing provider plugins...
- Finding hashicorp/google versions matching "4.51.0"...
- Installing hashicorp/google v4.51.0...
- Installed hashicorp/google v4.51.0 (signed by HashiCorp)
Terraform has created a lock file .terraform.lock.hcl to record the provider
selections it made above. Include this file in your version control repository
so that Terraform can guarantee to make the same selections by default when
you run "terraform init" in the future.

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ terraform validate
Success! The configuration is valid.

yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ terraform plan

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_bigquery_dataset.dataset will be created
  + resource "google_bigquery_dataset" "dataset" {
      + creation_time              = (known after apply)
      + dataset_id                 = "<The Dataset Name You Want to Use>"
      + delete_contents_on_destroy = false
      + etag                       = (known after apply)
      + id                         = (known after apply)
      + labels                     = (known after apply)
      + last_modified_time         = (known after apply)
      + location                   = "US"
      + project                    = "<Your Project ID>"
      + self_link                  = (known after apply)

      + access (known after apply)
    }

  # google_storage_bucket.data-lake-bucket will be created
  + resource "google_storage_bucket" "data-lake-bucket" {
      + force_destroy               = true
      + id                          = (known after apply)
      + location                    = "US"
      + name                        = "<Your Unique Bucket Name>"
      + project                     = (known after apply)
      + public_access_prevention    = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + uniform_bucket_level_access = true
      + url                         = (known after apply)

      + lifecycle_rule {
          + action {
              + type          = "Delete"
                # (1 unchanged attribute hidden)
            }
          + condition {
              + age                    = 30
              + matches_prefix         = []
              + matches_storage_class  = []
              + matches_suffix         = []
              + with_state             = (known after apply)
                # (3 unchanged attributes hidden)
            }
        }

      + versioning {
          + enabled = true
        }

      + website (known after apply)
    }

Plan: 2 to add, 0 to change, 0 to destroy.

───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Note: You didn't use the -out option to save this plan, so Terraform can't guarantee to take exactly these actions if you run "terraform apply" now.
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ terraform plan -out=plan.out

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_bigquery_dataset.dataset will be created
  + resource "google_bigquery_dataset" "dataset" {
      + creation_time              = (known after apply)
      + dataset_id                 = "<The Dataset Name You Want to Use>"
      + delete_contents_on_destroy = false
      + etag                       = (known after apply)
      + id                         = (known after apply)
      + labels                     = (known after apply)
      + last_modified_time         = (known after apply)
      + location                   = "US"
      + project                    = "<Your Project ID>"
      + self_link                  = (known after apply)

      + access (known after apply)
    }

  # google_storage_bucket.data-lake-bucket will be created
  + resource "google_storage_bucket" "data-lake-bucket" {
      + force_destroy               = true
      + id                          = (known after apply)
      + location                    = "US"
      + name                        = "<Your Unique Bucket Name>"
      + project                     = (known after apply)
      + public_access_prevention    = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + uniform_bucket_level_access = true
      + url                         = (known after apply)

      + lifecycle_rule {
          + action {
              + type          = "Delete"
                # (1 unchanged attribute hidden)
            }
          + condition {
              + age                    = 30
              + matches_prefix         = []
              + matches_storage_class  = []
              + matches_suffix         = []
              + with_state             = (known after apply)
                # (3 unchanged attributes hidden)
            }
        }

      + versioning {
          + enabled = true
        }

      + website (known after apply)
    }

Plan: 2 to add, 0 to change, 0 to destroy.

──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Saved the plan to: plan.out

To perform exactly these actions, run the following command to apply:
    terraform apply "plan.out"
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ terraform apply plan.out
google_bigquery_dataset.dataset: Creating...
google_storage_bucket.data-lake-bucket: Creating...
╷
│ Error: error: bucket name validation failed <Your Unique Bucket Name>. See https://cloud.google.com/storage/docs/naming-buckets
│ 
│   with google_storage_bucket.data-lake-bucket,
│   on main.tf line 19, in resource "google_storage_bucket" "data-lake-bucket":
│   19: resource "google_storage_bucket" "data-lake-bucket" {
│ 
╵
╷
│ Error: Error creating Dataset: googleapi: Error 400: Invalid resource name projects/<Your Project ID>; Project id: <Your Project ID>, badRequest
│ 
│   with google_bigquery_dataset.dataset,
│   on main.tf line 44, in resource "google_bigquery_dataset" "dataset":
│   44: resource "google_bigquery_dataset" "dataset" {
│ 
╵
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ terraform init
Initializing the backend...
Initializing provider plugins...
- Reusing previous version of hashicorp/google from the dependency lock file
- Using previously-installed hashicorp/google v4.51.0

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ terraform plan

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_bigquery_dataset.dataset will be created
  + resource "google_bigquery_dataset" "dataset" {
      + creation_time              = (known after apply)
      + dataset_id                 = "<The Dataset Name You Want to Use>"
      + delete_contents_on_destroy = false
      + etag                       = (known after apply)
      + id                         = (known after apply)
      + labels                     = (known after apply)
      + last_modified_time         = (known after apply)
      + location                   = "US"
      + project                    = "<Your Project ID>"
      + self_link                  = (known after apply)

      + access (known after apply)
    }

  # google_storage_bucket.data-lake-bucket will be created
  + resource "google_storage_bucket" "data-lake-bucket" {
      + force_destroy               = true
      + id                          = (known after apply)
      + location                    = "US"
      + name                        = "<Your Unique Bucket Name>"
      + project                     = (known after apply)
      + public_access_prevention    = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + uniform_bucket_level_access = true
      + url                         = (known after apply)

      + lifecycle_rule {
          + action {
              + type          = "Delete"
                # (1 unchanged attribute hidden)
            }
          + condition {
              + age                    = 30
              + matches_prefix         = []
              + matches_storage_class  = []
              + matches_suffix         = []
              + with_state             = (known after apply)
                # (3 unchanged attributes hidden)
            }
        }

      + versioning {
          + enabled = true
        }

      + website (known after apply)
    }

Plan: 2 to add, 0 to change, 0 to destroy.

────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Note: You didn't use the -out option to save this plan, so Terraform can't guarantee to take exactly these actions if you run "terraform apply" now.
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ nano main.tf
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ gcloud config list project

[core]
project = flash-rope-448018-n5

Your active configuration is: [default]
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ 
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ terraform plan -out=plan.out
 
Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_bigquery_dataset.dataset will be created
  + resource "google_bigquery_dataset" "dataset" {
      + creation_time              = (known after apply)
      + dataset_id                 = "terraform_dataset"
      + delete_contents_on_destroy = false
      + etag                       = (known after apply)
      + id                         = (known after apply)
      + labels                     = (known after apply)
      + last_modified_time         = (known after apply)
      + location                   = "US"
      + project                    = "870614746377"
      + self_link                  = (known after apply)

      + access (known after apply)
    }

  # google_storage_bucket.data-lake-bucket will be created
  + resource "google_storage_bucket" "data-lake-bucket" {
      + force_destroy               = true
      + id                          = (known after apply)
      + location                    = "US"
      + name                        = "yifan-wang-unique-bucket-1105"
      + project                     = (known after apply)
      + public_access_prevention    = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + uniform_bucket_level_access = true
      + url                         = (known after apply)

      + lifecycle_rule {
          + action {
              + type          = "Delete"
                # (1 unchanged attribute hidden)
            }
          + condition {
              + age                    = 30
              + matches_prefix         = []
              + matches_storage_class  = []
              + matches_suffix         = []
              + with_state             = (known after apply)
                # (3 unchanged attributes hidden)
            }
        }

      + versioning {
          + enabled = true
        }

      + website (known after apply)
    }

Plan: 2 to add, 0 to change, 0 to destroy.

───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Saved the plan to: plan.out

To perform exactly these actions, run the following command to apply:
    terraform apply "plan.out"
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ terraform apply plan.out
google_bigquery_dataset.dataset: Creating...
google_storage_bucket.data-lake-bucket: Creating...
google_bigquery_dataset.dataset: Creation complete after 1s [id=projects/870614746377/datasets/terraform_dataset]
╷
│ Error: googleapi: Error 400: Unknown project id: <Your Project ID>, invalid
│ 
│   with google_storage_bucket.data-lake-bucket,
│   on main.tf line 19, in resource "google_storage_bucket" "data-lake-bucket":
│   19: resource "google_storage_bucket" "data-lake-bucket" {
│ 
╵
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ nano main.tf
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ terraform init
Initializing the backend...
Initializing provider plugins...
- Reusing previous version of hashicorp/google from the dependency lock file
- Using previously-installed hashicorp/google v4.51.0

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ terraform plan -out=plan.out
google_bigquery_dataset.dataset: Refreshing state... [id=projects/870614746377/datasets/terraform_dataset]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create
  ~ update in-place

Terraform will perform the following actions:

  # google_bigquery_dataset.dataset will be updated in-place
  ~ resource "google_bigquery_dataset" "dataset" {
        id                              = "projects/870614746377/datasets/terraform_dataset"
      - max_time_travel_hours           = "168" -> null
        # (13 unchanged attributes hidden)

        # (4 unchanged blocks hidden)
    }

  # google_storage_bucket.data-lake-bucket will be created
  + resource "google_storage_bucket" "data-lake-bucket" {
      + force_destroy               = true
      + id                          = (known after apply)
      + location                    = "US"
      + name                        = "yifan-wang-unique-bucket-1105"
      + project                     = (known after apply)
      + public_access_prevention    = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + uniform_bucket_level_access = true
      + url                         = (known after apply)

      + lifecycle_rule {
          + action {
              + type          = "Delete"
                # (1 unchanged attribute hidden)
            }
          + condition {
              + age                    = 30
              + matches_prefix         = []
              + matches_storage_class  = []
              + matches_suffix         = []
              + with_state             = (known after apply)
                # (3 unchanged attributes hidden)
            }
        }

      + versioning {
          + enabled = true
        }

      + website (known after apply)
    }

Plan: 1 to add, 1 to change, 0 to destroy.

───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Saved the plan to: plan.out

To perform exactly these actions, run the following command to apply:
    terraform apply "plan.out"
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ terraform apply plan.out
google_bigquery_dataset.dataset: Modifying... [id=projects/870614746377/datasets/terraform_dataset]
google_storage_bucket.data-lake-bucket: Creating...
google_bigquery_dataset.dataset: Modifications complete after 1s [id=projects/870614746377/datasets/terraform_dataset]
google_storage_bucket.data-lake-bucket: Creation complete after 2s [id=yifan-wang-unique-bucket-1105]

Apply complete! Resources: 1 added, 1 changed, 0 destroyed.
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ terraform show
# google_bigquery_dataset.dataset:
resource "google_bigquery_dataset" "dataset" {
    creation_time                   = 1737589755062
    dataset_id                      = "terraform_dataset"
    default_partition_expiration_ms = 0
    default_table_expiration_ms     = 0
    delete_contents_on_destroy      = false
    description                     = null
    etag                            = "PWOyBlF03+k9yTuxEnXo5w=="
    friendly_name                   = null
    id                              = "projects/870614746377/datasets/terraform_dataset"
    labels                          = {}
    last_modified_time              = 1737589981213
    location                        = "US"
    max_time_travel_hours           = "168"
    project                         = "870614746377"
    self_link                       = "https://bigquery.googleapis.com/bigquery/v2/projects/870614746377/datasets/terraform_dataset"

    access {
        domain         = null
        group_by_email = null
        role           = "OWNER"
        special_group  = null
        user_by_email  = "870614746377-compute@developer.gserviceaccount.com"
    }
    access {
        domain         = null
        group_by_email = null
        role           = "OWNER"
        special_group  = "projectOwners"
        user_by_email  = null
    }
    access {
        domain         = null
        group_by_email = null
        role           = "READER"
        special_group  = "projectReaders"
        user_by_email  = null
    }
    access {
        domain         = null
        group_by_email = null
        role           = "WRITER"
        special_group  = "projectWriters"
        user_by_email  = null
    }
}

# google_storage_bucket.data-lake-bucket:
resource "google_storage_bucket" "data-lake-bucket" {
    default_event_based_hold    = false
    force_destroy               = true
    id                          = "yifan-wang-unique-bucket-1105"
    location                    = "US"
    name                        = "yifan-wang-unique-bucket-1105"
    project                     = "870614746377"
    public_access_prevention    = "inherited"
    requester_pays              = false
    self_link                   = "https://www.googleapis.com/storage/v1/b/yifan-wang-unique-bucket-1105"
    storage_class               = "STANDARD"
    uniform_bucket_level_access = true
    url                         = "gs://yifan-wang-unique-bucket-1105"

    lifecycle_rule {
        action {
            storage_class = null
            type          = "Delete"
        }
        condition {
            age                        = 30
            created_before             = null
            custom_time_before         = null
            days_since_custom_time     = 0
            days_since_noncurrent_time = 0
            matches_prefix             = []
            matches_storage_class      = []
            matches_suffix             = []
            noncurrent_time_before     = null
            num_newer_versions         = 0
            with_state                 = "ANY"
        }
    }

    versioning {
        enabled = true
    }
}
yifan_wang1105@docker-19jan:~/postgres_project/data-engineering-zoomcamp/01-docker-terraform/1_terraform_gcp/terraform/terraform_basic$ 
